# 资产抽取流程（Step1～Step3）与数据库设计（落地版）

> **目标**：将“非结构化剧本”转化为“结构化资产库”的过程工程化。支持 **Step2→Step3 的可重复运行、可追溯、可人工修订、可增量更新**。
> **核心结论**：采用 **“行级数据模型”** 为主，**无外键（No Foreign Keys）设计**，依靠应用层逻辑维护关联，最大限度提升写入性能与 schema 变更灵活性。

---

## 一、 核心工序拆解

### Step 1: 剧本标准化 (Standardization)
**任务**：为剧本的每一行/每一段打上唯一“坐标”。
- **输入**：原始剧本文本。
- **输出**：带行号的结构化文本（`Sxx.Lyy`）。
- **目的**：后续所有“证据”都必须锚定到具体的 `line_id`，实现“点击证据跳转原文”的功能。

### Step 2: 候选实体抽取 (Candidate Extraction)
**任务**：利用 LLM 尽可能多地“召回”实体，宁滥勿缺。
- **输入**：标准化剧本片段。
- **输出**：候选实体列表。每个实体包含：
  - `原名`：剧本中出现的原始名字（如“老张”、“张局长”）。
  - `类型`：人物/场景/道具。
  - `证据`：原文中的具体句子（引用）。
- **特点**：此时尚未归并，同一人物可能有多个“候选实体”（如“老张”和“张局长”是两条记录）。

### Step 3: 实体归一化与入库 (Normalization & Decision)
**任务**：将 Step 2 的碎片化实体“归并”为规范资产，并判定是否入库。
- **输入**：Step 2 的候选实体表。
- **输出**：规范资产表。
  - **归并 (Merge)**：将“老张”、“张局长”映射到同一个规范资产“张三”。
  - **判定 (Gate)**：决定“张三”是否是有价值的资产（入库/丢弃）。

---

## 二、 数据库设计方案

### 0) 设计原则
1.  **无外键约束 (No Foreign Keys)**：所有关联字段（如 `project_uid`）仅作**逻辑关联**，数据库层面**不设外键约束**。数据完整性由应用层代码保证。
    - *理由*：避免分布式场景下的约束性能损耗，方便测试数据清理，方便 schema 变更。
2.  **行级存储**：候选实体、证据、规范资产均独立存行，支持前端表格级的增删改查。
3.  **运行溯源 (Run Traceability)**：所有的抽取动作都关联一个 `run_id`。
4.  **软删除**：核心数据表建议加 `is_deleted` 标记，而非物理删除。

### A. 基础层：项目与剧本

#### 1. 项目表 `project`
管理整体项目空间。
- `uid` (PK, String): 雪花ID/UUID
- `name` (String): 项目名称
- `description` (Text): 项目描述
- `created_at`, `updated_at`

#### 2. 剧本表 `script`
存储原始上传的剧本。
- `uid` (PK, String)
- `project_uid` (String, Index): 逻辑关联项目。
- `name` (String): 剧本名（如“第一集”）
- `content` (LongText): 原始完整文本
- `created_at`, `updated_at`

#### 3. 标准化剧本表 `normalized_script`
存储处理后的“带坐标”剧本。
- `uid` (PK, String)
- `script_uid` (String, Index): 逻辑关联剧本。
- `version` (String): 只有剧本内容变更时才生成新版本（v1, v2...）
- `content_json` (JSON): 核心存储字段。
  ```json
  [
    {"line_id": "S01.L01", "text": "（日，内，警局）", "type": "scene_header"},
    {"line_id": "S01.L02", "text": "老张：这案子不好办。", "type": "dialogue"}
  ]
  ```
- `created_at`

---

### B. 运行控制层：追踪每一次 AI 调用

#### 4. 抽取运行记录表 `extraction_run`
核心表。记录“谁，在什么时候，用什么配置，跑了哪一步”。
- `uid` (PK, String)
- `project_uid` (String, Index): 逻辑关联项目。
- `script_uid` (String, Index): 逻辑关联剧本。
- `step` (Int): `2` (候选抽取) 或 `3` (归一化)
- `status` (String): `running` / `completed` / `failed`
- `model_config` (JSON): 记录模型名、Temperature、Prompt快照（或Prompt ID）。
  - *作用*：如果发现效果不好，可以调出当时的 Prompt 进行 debug。
- `created_at`, `finished_at`

#### 5. 产物快照表 `artifact_snapshot` (辅助)
用于“存档”。每次运行结束后，将结果存一份完整的 JSON 文件。
- `uid` (PK)
- `run_uid` (String, Index): 逻辑关联 `extraction_run`。
- `content_json` (LongJSON): 完整的 LLM 原始输出或整理后的全量数据。
- *作用*：用于快速复现、审计、以及在“行级数据”被人工改乱后进行对照恢复。

---

### C. 核心数据层：Step 2 & Step 3

#### 6. 候选实体表 `candidate_entity` (Step 2 产物)
存储 LLM 第一次从文中“抠”出来的实体。
- `uid` (PK)
- `run_uid` (String, Index): 逻辑关联 `extraction_run` (Step 2)。
- `raw_name` (String): 原文中的称呼（如“王总”）。
- `entity_type` (String): `person` / `scene` / `prop` / `other`。
- `confidence` (Float): AI 自信度（可选）。
- `canonical_asset_uid` (String, Index, Nullable): **关键字段**。逻辑指向 `canonical_asset`。
  - *逻辑*：初始为空。在 Step 3 运行后，或者人工校对时，将此字段填上，表示“这个候选实体属于那个规范资产”。
- `created_at`

#### 7. 候选证据表 `candidate_evidence`
支持“一对多”证据。
- `uid` (PK)
- `candidate_uid` (String, Index): 逻辑关联 `candidate_entity`。
- `line_id` (String): 关联 `normalized_script` 中的行号（字符串匹配）。
- `quote` (String): 原文引用片段（用于展示，避免每次都去查剧本表）。
- `reason` (String): AI 提取的理由（可选）。

> **设计决策**：为什么不用 JSON 存证据？
> 答：为了支持**精细化修订**。用户可能想删除某一条错误的证据，保留其他正确的证据。独立表结构对此支持更好。

#### 8. 规范资产表 `canonical_asset` (Step 3 产物)
经过归并、清洗后的“主数据”。
- `uid` (PK)
- `project_uid` (String, Index): 逻辑关联项目（跨剧本）。
- `run_uid` (String, Index): 最近一次更新它的运行 ID。
- `name` (String): 规范名称（如“王建国”）。
- `type` (String): `person` / `scene` / `prop`。
- `aliases` (JSON): 别名列表。例：`["王总", "老王", "建国"]`。
- `description` (Text): 简短描述/人设摘要。
- `status` (String): `in_pool` (入库) / `discarded` (废弃) / `review_needed` (待人工确认)。
- `created_at`, `updated_at`

---

## 三、 关键业务流程的数据流转

### 场景 1：自动抽取与归并
1.  **启动 Step 2**：
    - 创建 `extraction_run (step=2)`。
    - LLM 分析剧本，输出候选列表。
    - 写入 `candidate_entity` 和 `candidate_evidence`。
2.  **启动 Step 3**：
    - 创建 `extraction_run (step=3)`。
    - 读取 `candidate_entity`（未归并的数据）。
    - LLM 进行聚类分析，决定哪些 ID 属于同一个人。
    - 写入/更新 `canonical_asset`。
    - **回填**：将 `candidate_entity.canonical_asset_uid` 更新为对应的 `canonical_asset.uid`。

### 场景 2：人工修订 (Human-in-the-loop)
- **修正证据**：用户发现某条证据提取错了 -> 直接删除 `candidate_evidence` 中对应的行。
- **修正归并**：用户发现“小李”被错误归并到了“老张”名下 -> 修改 `candidate_entity` 中“小李”记录的 `canonical_asset_uid`，将其指向正确的资产或新建一个资产。
- **修正入库判定**：用户觉得“路人甲”不应该入库 -> 将 `canonical_asset` 中“路人甲”的 `status` 改为 `discarded`。

---

## 四、 索引建议 (Performance)

虽然没有外键约束，但为了查询性能，**必须建立索引**：

1.  `script(project_uid)`
2.  `normalized_script(script_uid)`
3.  `extraction_run(project_uid)`
4.  `candidate_entity(run_uid)`
5.  `candidate_entity(canonical_asset_uid)`: **高频查询**。
6.  `candidate_evidence(candidate_uid)`
7.  `canonical_asset(project_uid, type)`

## 五、 后续扩展 (Step 4)

本文档主要覆盖**抽取**阶段。后续的**资产卡片生成 (Step 4)** 将基于 `canonical_asset` 表：
- 对状态为 `in_pool` 的资产，进一步调用 LLM 生成详细的 `asset_profile`（外貌、性格、高光时刻等）。
- `asset_profile` 可以设计为一张新表，与 `canonical_asset` 是一对一关系（同样逻辑关联）。
